{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce GTX 1060 6GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "   \n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/news_pickle/all_sentence_0716.pkl', 'rb') as f:\n",
    "    df_all = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 110,486\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82938</th>\n",
       "      <td>While the government was preparing to ban mass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43227</th>\n",
       "      <td>PARIS (Reuters) - An 80-year-old Chinese touri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106927</th>\n",
       "      <td>Three Formula One Grand Prix, in Azerbaijan, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19374</th>\n",
       "      <td>Today the University of Washington in Seattle,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113350</th>\n",
       "      <td>\"I'm not just asking you to help New York,\" he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7710</th>\n",
       "      <td>There were 211 people on the initial manifest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44633</th>\n",
       "      <td>Rospotrebnadzor, the country’s consumer safety...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94668</th>\n",
       "      <td>To avert a spike in unemployment, the governme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115311</th>\n",
       "      <td>China will ban entry to all foreigners, includ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61872</th>\n",
       "      <td>Health officials and front-line medical staff ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentences\n",
       "82938   While the government was preparing to ban mass...\n",
       "43227   PARIS (Reuters) - An 80-year-old Chinese touri...\n",
       "106927  Three Formula One Grand Prix, in Azerbaijan, S...\n",
       "19374   Today the University of Washington in Seattle,...\n",
       "113350  \"I'm not just asking you to help New York,\" he...\n",
       "7710    There were 211 people on the initial manifest ...\n",
       "44633   Rospotrebnadzor, the country’s consumer safety...\n",
       "94668   To avert a spike in unemployment, the governme...\n",
       "115311  China will ban entry to all foreigners, includ...\n",
       "61872   Health officials and front-line medical staff ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of training sentences: {:,}\\n'.format(df_all.shape[0]))\n",
    "\n",
    "df_all.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df_all.sentences.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The new Chinese virus which has already spread abroad \"is still preventable and controllable\", China says.',\n",
       "       'Its National Health Commission warned, however, that close monitoring was needed given the source, transmission and mutation methods were unknown.',\n",
       "       'Two people are known to have died from the respiratory illness which appeared in Wuhan city in December.',\n",
       "       ...,\n",
       "       'On Tuesday, the presidency announced it would release 1,420 prisoners in an amnesty to alleviate crowding in prisons.',\n",
       "       'According to the statement, President Kais Saied also ordered increased sanitation measures in jails.',\n",
       "       'Saied last week ordered the army to deploy in the streets to force people to respect the lockdown.Â\\xa0'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tokenization & Input Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Token to Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/wiki_entity/entity_list_0716.pkl','rb') as f:\n",
    "    entities = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_entity = []\n",
    "for i, entity in enumerate(entities):\n",
    "    if len(entity.split()) == 1:\n",
    "        new_entity.append(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_added_toks = tokenizer.add_tokens(new_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoded_entity = tokenizer.convert_tokens_to_ids(new_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original: ', sentences[6])\n",
    "\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences[6]))\n",
    "\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[6])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/tokenizer.pkl','wb') as f:\n",
    "    pkl.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import copy\n",
    "import random\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "label_masks = []\n",
    "\n",
    "for sent in tqdm_notebook(sentences):\n",
    "    try:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sent,                      \n",
    "                            add_special_tokens = True, \n",
    "                            max_length = 16,\n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True,\n",
    "                            return_tensors = 'pt',\n",
    "                       )\n",
    "\n",
    "        \n",
    "        input_id = encoded_dict['input_ids']\n",
    "\n",
    "        \n",
    "        label_mask = copy.deepcopy(encoded_dict['input_ids'])\n",
    "\n",
    "        cond = 0\n",
    "        for i, i_id in enumerate(input_id[0]):\n",
    "            if i_id.item() in encoded_entity:\n",
    "                if cond < 2:\n",
    "                    input_id[0,i] = 103\n",
    "                    cond += 1\n",
    "                else:\n",
    "                    break\n",
    "                    \n",
    "        if cond == 0:\n",
    "            sen_len = sum(encoded_dict['attention_mask'][0]).item()\n",
    "            sen_list = list(range(1,sen_len))\n",
    "            random.seed(42)\n",
    "            ran_list = random.sample(sen_list, 2)\n",
    "\n",
    "            for j in ran_list:\n",
    "                input_id[0,j] = 103\n",
    "            \n",
    "        elif cond == 1:\n",
    "            sen_len = sum(encoded_dict['attention_mask'][0]).item()\n",
    "            sen_list = list(range(1,sen_len))\n",
    "            random.seed(42)\n",
    "            ran_list = random.sample(sen_list, 1)\n",
    "            \n",
    "            while i in ran_list:\n",
    "                ran_list = random.sample(sen_list, 1)\n",
    "                \n",
    "            for k in ran_list:\n",
    "                input_id[0,k] = 103\n",
    "                \n",
    "        input_ids.append(input_id)\n",
    "        label_masks.append(label_mask)\n",
    "\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "        \n",
    "    except:\n",
    "        print(sent)\n",
    "        pass\n",
    "    \n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels=torch.cat(label_masks, dim= 0)\n",
    "\n",
    "\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])\n",
    "print('label:', label_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/encoded_token/en_tokens_50k.pkl','wb') as f:\n",
    "    pkl.dump(input_ids, f)\n",
    "    pkl.dump(attention_masks, f)\n",
    "    pkl.dump(labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
